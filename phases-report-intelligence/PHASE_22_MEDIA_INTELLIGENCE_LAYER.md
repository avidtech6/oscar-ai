ğŸ“˜ PHASE 22 â€” MEDIA INTELLIGENCE LAYER
Images, Diagrams, Gallery, Voice Notes, Transcription, and AIâ€‘Driven Media Placement
â­ OVERVIEW
Phase 22 introduces the Media Intelligence Layer, enabling Oscar AI to:

Detect images, diagrams, screenshots, and camera photos

Save all media to a unified Gallery

Autoâ€‘tag media with context

Understand relationships between images (e.g., â€œplace next to previous diagramâ€)

Capture voice notes

Transcribe audio

Insert media into notes, reports, blog posts, and tasks

Trigger AI nudges when new media appears

Support camera + microphone in every prompt box

This phase gives Oscar AI the sensory capabilities needed for a true Copilot experience.

â­ 1. MEDIA INGESTION PIPELINE
Supported ingestion methods:
Paste (Ctrl+V)

Dragâ€‘andâ€‘drop

File upload

Camera capture

Screenshot paste

Mobile photo input

Pipeline steps:
Detect media

Save to Gallery (IndexedDB)

Autoâ€‘tag with:

page

itemId

mediaType: photo | diagram | screenshot | audio

timestamp

Emit event:  
onMediaAdded(media, context)

Trigger AI nudge (optional)

Make media available for AI actions

â­ 2. GALLERY SYSTEM
Requirements:
Stored in IndexedDB

Queryable by tags

Supports:

rename

delete

reâ€‘tag

preview

Accessible from:

Notes

Reports

Blog Writer

Tasks

Global Assistant

Gallery metadata:
ts
{
  id: string,
  type: 'photo' | 'diagram' | 'screenshot' | 'audio',
  tags: string[],
  context: {
    page: string,
    itemId?: string
  },
  createdAt: number,
  blob: Blob
}
â­ 3. IMAGE & DIAGRAM INTELLIGENCE
AI must understand:
When a diagram is added

When a photo is added

When two images should be placed sideâ€‘byâ€‘side

When a user references â€œthe previous diagramâ€

When a user references â€œthe photo I just tookâ€

Supported actions:
Insert image into document

Place image next to another image

Create twoâ€‘column layout

Label diagrams

Resize images

Replace images

Move images

Example user prompts:
â€œPut the photo I just took next to the diagram in Section 3.â€

â€œLabel this diagram with crown spread and RPA.â€

â€œReplace the old image with the new one.â€

AI uses Gallery + context to resolve references.

â­ 4. VOICE NOTE PIPELINE
Every prompt box includes:
ğŸ¤ Microphone (speechâ€‘toâ€‘text)

ğŸ™ Voice Note (audio file capture)

Voice note behaviour:
Save audio to Gallery

Autoâ€‘tag with context

Emit event:
onVoiceNoteAdded(audio, context)

AI asks:

â€œTranscribe this into the document? Where should it go?â€

If user chooses a location â†’ AI inserts text

If not â†’ voice note stays in Notes

Transcription:
Realâ€‘time for microphone

Postâ€‘processing for voice notes

â­ 5. AI NUDGE SYSTEM FOR MEDIA
Triggered when:

Image added

Diagram added

Voice note added

Screenshot pasted

Example nudges:
â€œInsert this into the report?â€

â€œPlace this next to the previous diagram?â€

â€œTranscribe this voice note?â€

â€œLabel this diagram?â€

Nudges appear as:

Microâ€‘cue (!)

Small bubble above assistant bar

Never intrusive.

â­ 6. MEDIAâ€‘AWARE CONTEXT MODE
When editing a document (note/report/blog):

AI can:
Insert media

Move media

Replace media

Resize media

Create layout blocks

Add captions

Add labels

Generate figure descriptions

AI must respect:
Manual editing

User overrides

Undo/redo

â­ 7. MEDIAâ€‘AWARE CHAT MODE
If user asks:

â€œWhat does this diagram show?â€

â€œExplain the photo I just added.â€

â€œDescribe the tree damage in this image.â€

AI switches to Chat Mode but retains media context.

After answering:

â€œApply this description to the report section we were working on?â€

If yes â†’ insert
If no â†’ keep in chat only

â­ 8. PROMPT BOX MEDIA CONTROLS
Every prompt box includes:

ğŸ“· Camera

ğŸ¤ Microphone

ğŸ™ Voice note

ğŸ“ File upload

ğŸ’¡ Smart hint line

ğŸ” Context chips

â¬†ï¸ Maximise button

Smart hints adapt to media:
â€œInsert image from Galleryâ€

â€œTranscribe voice noteâ€

â€œPlace photo next to diagramâ€

â­ 9. EVENT MODEL (MEDIAâ€‘FOCUSED)
Assistant listens for:
onMediaAdded(media, context)

onVoiceNoteAdded(audio, context)

onPaste(text, context)

onGalleryUpdate()

Assistant emits:
insertMedia(itemId, mediaId, position)

replaceMedia(itemId, oldId, newId)

labelDiagram(itemId, mediaId, labels)

transcribeAudio(audioId)

nudge(type, message)

â­ 10. COMPLETION CRITERIA
Phase 22 is complete when:

Images save to Gallery

Voice notes save to Gallery

Autoâ€‘tagging works

AI nudges appear for media

AI can insert images into documents

AI can place images sideâ€‘byâ€‘side

AI can label diagrams

AI can transcribe voice notes

Prompt box has camera + mic + voice note

Mediaâ€‘aware context mode works

Mediaâ€‘aware chat mode works

Event model implemented