ğŸ“˜ PHASE 0 â€” MASTER VISION DOCUMENT FOR THE OSCAR AI COPILOT LAYER
The Intelligence Layer of the Workspace: Subtle, Aware, Helpful, and Always Present
â­ INTRODUCTION
Oscar AI is not â€œan app with AI features.â€
Oscar AI is a workspace with an intelligence layer woven through every surface.

The Copilot layer is the system that:

Watches what the user is doing

Understands the context

Offers subtle, optional help

Reacts instantly to new content

Edits documents, notes, reports, and blog posts

Handles images, diagrams, and voice notes

Stores contextual chat history

Switches between chat mode and context mode

Lives everywhere, but never intrudes

This document defines the vision, principles, architecture, and behaviour of the Copilot layer.

It is the foundation for all subsequent phases.

â­ 1. THE CORE PHILOSOPHY
Oscar AI must feel:

Subtle â€” never intrusive

Powerful â€” always capable

Aware â€” understands context

Respectful â€” user stays in control

Predictable â€” consistent behaviour

Flexible â€” works across all pages

Humanâ€‘centred â€” enhances manual editing, never replaces it

The assistant should feel like:

â€œThe app is working with me, not for me.â€

â­ 2. THE COPILOT LAYER
The Copilot layer is made of three subsystems:

A. The Brain (Phase 21)
Global assistant bar

Context chips

Smart hints

Microâ€‘cues

Chat Mode vs Context Mode

Modalâ€‘attached assistant

Contextual chat history

Maximise â†’ filtered chat

Multiâ€‘select AI actions

Event model

B. The Senses (Phase 22)
Image ingestion

Diagram understanding

Gallery system

Voice notes

Transcription

Mediaâ€‘aware AI actions

Mediaâ€‘aware nudges

C. The Hands (Phase 23+)
Layout engine

Section generation

Rewriting

Summaries

Insertions

Reordering

Table generation

Diagram labelling

Multiâ€‘document workflows

Together, these form the Oscar AI Copilot OS.

â­ 3. THE GLOBAL ASSISTANT
The assistant is:

Always visible

Always available

Always contextâ€‘aware

Always collapsible

Always respectful

Desktop:
Bottom bar

Expandable panel

Maximise button

Mobile:
Thin bottom bar

Fullâ€‘screen panel

The assistant is the primary interaction layer.

â­ 4. CONTEXT AWARENESS
The assistant must always know:

What page the user is on

What item is open

What items are selected

Whether a modal is open

Whether the user is editing

Whether the user is chatting

Whether new media was added

Whether the user changed context

This is powered by a global context store.

â­ 5. CHAT MODE VS CONTEXT MODE
Context Mode
Editing a note/report/blog/task

AI actions apply directly

Context chips visible

Smart hints relevant

Chat Mode
Triggered when user asks a general question.

Behaviour:

Page slides into background

Chat window becomes primary

Assistant answers normally

After conversation:

â€œApply this to the document we were working on?â€

If yes â†’ content inserted
If no â†’ stays in chat only

â­ 6. MEDIA INTELLIGENCE
Oscar AI must understand:

Images

Diagrams

Screenshots

Camera photos

Voice notes

Audio recordings

Media is:

Saved to Gallery

Autoâ€‘tagged

Available for AI actions

Triggering nudges

AI can:

Insert images

Place images sideâ€‘byâ€‘side

Label diagrams

Transcribe audio

Insert transcriptions

Replace images

Move images

â­ 7. NUDGE SYSTEM
Nudges are:

Optional

Subtle

Contextâ€‘aware

Triggered by events

Examples:

â€œInsert this image into the report?â€

â€œTranscribe this voice note?â€

â€œRewrite this section?â€

â€œMark selected tasks as done?â€

Nudges appear as:

Microâ€‘cue (!)

Small bubble above assistant bar

â­ 8. CONTEXTUAL CHAT HISTORY
Rules:

Stored per item

Hidden by default

Only shown when user asks

Maximise button opens filtered chat

Clearly labelled

Colourâ€‘coded

Inside the item:

Only one AI bubble appears
(â€œContent added.â€)

â­ 9. MULTIâ€‘SELECT AI ACTIONS
Supported on:

Tasks

Notes

Projects

Reports

Blog posts

Examples:

â€œMark all selected tasks as doneâ€

â€œTag selected notes as BS5837â€

â€œGenerate a combined reportâ€

â­ 10. PROMPT BOX DESIGN
Every prompt box includes:

ğŸ“· Camera

ğŸ¤ Microphone

ğŸ™ Voice note

ğŸ“ File upload

ğŸ’¡ Smart hint line

ğŸ” Context chips

â¬†ï¸ Maximise button

â­ 11. MODALâ€‘ATTACHED ASSISTANT
When editing in a modal:

Assistant attaches inside modal

Sticks to bottom

Context chips show item

Smart hints adapt

AI actions apply only to that item

â­ 12. ONEâ€‘BUBBLE CONFIRMATION RULE
When AI applies content:

Only one bubble appears

No chat history

No clutter

â­ 13. EVENT MODEL
Assistant listens for:

Page changes

Item open/close

Selection changes

Media added

Voice note added

Modal open/close

Paste events

Assistant emits:

Insert content

Rewrite content

Insert media

Replace media

Label diagrams

Transcribe audio

Create notes/tasks

Nudges

â­ 14. USER CONTROL
The user can always:

Edit manually

Resize images

Move content

Undo/redo

Reject nudges

Decline â€œapply this?â€ prompts

Collapse assistant

Switch to chat mode

Filter chat history

AI never overrides manual editing.

â­ 15. COMPLETION CRITERIA FOR THE COPILOT LAYER
The Copilot layer is complete when:

Assistant is global

Assistant is contextâ€‘aware

Assistant handles media

Assistant handles voice

Assistant handles layout

Assistant handles multiâ€‘select

Assistant handles chat mode

Assistant handles context mode

Assistant stores contextual chat

Assistant nudges intelligently

Assistant integrates with all pages

Assistant feels subtle but powerful